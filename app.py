import streamlit as st
import pandas as pd
import fitz  # Using standard alias for PyMuPDF
import re
from datetime import datetime, timedelta
import plotly.express as px
from sentence_transformers import SentenceTransformer, util
from geopy.geocoders import Nominatim
from geopy.extra.rate_limiter import RateLimiter
import os
from dotenv import load_dotenv
import csv
import io
import requests
import pytz
import json

# --- LLM Specific Imports ---
import google.generativeai as genai
from langchain_groq import ChatGroq
from langchain_core.messages import SystemMessage, HumanMessage

# --- API Key Setup ---
load_dotenv()
groq_api_key = os.getenv("GROQ_API_KEY") or st.secrets.get("GROQ_API_KEY")
google_api_key = os.getenv("GOOGLE_API_KEY") or st.secrets.get("GOOGLE_API_KEY")
openweathermap_api_key = os.getenv("OPENWEATHER_API_KEY") or st.secrets.get("OPENWEATHER_API_KEY")

# ------------------------
# Streamlit Page Config & Style
# ------------------------
st.set_page_config(page_title="Auckland Air Discharge Consent Dashboard", layout="wide", page_icon="üá≥üáø")

# Configure Gemini AI
if google_api_key:
    genai.configure(api_key=google_api_key)
else:
    st.error("Google API key not found. AI-powered features will be offline.")

# --- UI & Display Functions ---

@st.cache_data(ttl=600)
def get_auckland_weather():
    """Fetches current weather for Auckland."""
    if not openweathermap_api_key:
        return "Weather Offline"
    url = f"https://api.openweathermap.org/data/2.5/weather?q=Auckland,nz&units=metric&appid={openweathermap_api_key}"
    try:
        response = requests.get(url, timeout=5)
        response.raise_for_status()
        data = response.json()
        temp = data["main"]["temp"]
        desc = data["weather"][0]["description"].title()
        return f"{desc}, {temp:.1f}¬∞C"
    except requests.exceptions.RequestException:
        return "Weather Unavailable"
    except Exception:
        return "Weather Error"

def display_header():
    """Renders the main header and live info banner."""
    nz_time = datetime.now(pytz.timezone("Pacific/Auckland"))
    today_str = nz_time.strftime("%A, %d %B %Y")
    current_time_str = nz_time.strftime("%I:%M %p")
    weather_str = get_auckland_weather()

    st.markdown(f"""
        <div style='text-align:center; padding:12px; font-size:1.2em; background-color:#333;
                     border-radius:10px; margin-bottom:20px; font-weight:500; color:white;'>
            üìç <strong>Auckland</strong> &nbsp;&nbsp;&nbsp; üìÖ <strong>{today_str}</strong> &nbsp;&nbsp;&nbsp; ‚è∞ <strong>{current_time_str}</strong> &nbsp;&nbsp;&nbsp; üå¶Ô∏è <strong>{weather_str}</strong>
        </div>
    """, unsafe_allow_html=True)
    st.markdown("""
        <h1 style='color:#2c6e91; text-align:center; font-size:2.8em; font-family: Quicksand, sans-serif;'>
            Auckland Air Discharge Consent Dashboard
        </h1>
    """, unsafe_allow_html=True)
    st.markdown("---")

# --- CORE UTILITY FUNCTIONS ---

def localize_to_auckland(dt):
    """Localizes a datetime object to Pacific/Auckland timezone."""
    if pd.isna(dt) or not isinstance(dt, datetime):
        return pd.NaT
    auckland_tz = pytz.timezone("Pacific/Auckland")
    if dt.tzinfo is None:
        return auckland_tz.localize(dt, is_dst=None)
    else:
        return dt.astimezone(auckland_tz)

def check_expiry(expiry_date):
    """Checks the status of a consent based on a pre-localized, timezone-aware expiry date."""
    if pd.isna(expiry_date):
        return "Unknown"
    current_nz_time = datetime.now(pytz.timezone("Pacific/Auckland"))
    return "Expired" if expiry_date < current_nz_time else "Active"

@st.cache_data(show_spinner="Geocoding addresses...")
def geocode_address(address):
    """Gets latitude and longitude for a given address string."""
    if not isinstance(address, str) or not address.strip():
        return (None, None)
    
    # Standardize for better matching
    standardized_address = address.strip()
    if 'auckland' not in standardized_address.lower():
        standardized_address += ", Auckland, New Zealand"
    
    try:
        geolocator = Nominatim(user_agent="auckland_air_discharge_dashboard_v3")
        geocode = RateLimiter(geolocator.geocode, min_delay_seconds=1)
        location = geocode(standardized_address)
        return (location.latitude, location.longitude) if location else (None, None)
    except Exception as e:
        st.warning(f"Geocoding error for '{standardized_address}': {e}")
        return (None, None)

# --- METADATA EXTRACTION FUNCTIONS ---

@st.cache_data(show_spinner="Extracting metadata with AI...")
def extract_metadata_with_llm(text_blob: str, file_name: str) -> dict:
    """(Primary Method) Extracts metadata using the Gemini LLM for robustness."""
    if not google_api_key:
        return {} # Signal failure to fallback

    model = genai.GenerativeModel("models/gemini-1.5-flash-latest")
    json_schema = {
        "Resource Consent Numbers": "string", "Company Name": "string", "Address": "string",
        "Issue Date": "string (DD-MM-YYYY)", "Expiry Date": "string (DD-MM-YYYY or relative duration like '35 years')",
        "AUP(OP) Triggers": "string", "Reason for Consent": "string (brief summary)",
        "Consent Conditions": "string (full text of conditions)"
    }
    prompt = f"""
    Analyze the text from the document '{file_name}'. Extract the information and format it as a JSON object matching the schema.
    If info is missing, use "Unknown". For expiry, extract the exact date or the duration text (e.g., "35 years").
    Your output MUST be only the JSON object, nothing else.

    Schema: {json.dumps(json_schema)}
    --- DOCUMENT TEXT ---
    {text_blob[:200000]} 
    --- END TEXT ---
    JSON Output:
    """
    try:
        response = model.generate_content(prompt)
        # Clean response to ensure it's valid JSON
        cleaned_text = response.text.strip().lstrip("```json").rstrip("```").strip()
        extracted_data = json.loads(cleaned_text)
        extracted_data["Text Blob"] = text_blob
        return extracted_data
    except Exception:
        # If any error (JSON parsing, API error), return empty dict to trigger fallback
        st.warning(f"AI extraction failed for {file_name}. Attempting regex fallback.")
        return {}

def extract_metadata_regex(text: str) -> dict:
    """(Fallback Method) Extracts metadata using regular expressions."""
    # Helper to find first match from a list of patterns
    def find_first(patterns, text_block):
        for p in patterns:
            match = re.search(p, text_block, re.IGNORECASE | re.DOTALL)
            if match:
                return match.group(1).strip()
        return "Unknown"

    rc_str = find_first([r"Application number(?:s)?:\s*([^A-Z]+)"], text)
    company_str = find_first([r"Applicant's name:\s*(.+?)\s*Site address"], text)
    address_str = find_first([r"Site address:\s*(.+?)(?=\s*Legal description)"], text)
    
    # BUG FIX: The problematic if/else block that printed to the screen has been removed.
    issue_date_str = find_first([
        r"Date:\s*(\d{1,2}\s+[A-Za-z]+\s+\d{4})",
        r"Date:\s*(\d{1,2}[/-]\d{1,2}[/-]\d{2,4})"
    ], text)
    
    expiry_date_str = find_first([
        r"expire\s+on\s+the\s*(\d{1,2}(?:st|nd|rd|th)?\s+of\s+[A-Za-z]+\s+\d{4})",
        r"expire\s+on\s*(\d{1,2}[/-]\d{1,2}[/-]\d{4})",
        r"expire[s]?\s+(\d+\s+years)"
    ], text)

    proposal_str = find_first([r"Proposal\s*:\s*(.+?)(?=\n[A-Z]|\.)"], text)
    conditions_match = re.search(r"(?<=Conditions).*?(?=Advice notes)", text, re.DOTALL | re.IGNORECASE)
    conditions_str = conditions_match.group(0).strip() if conditions_match else "Unknown"
    
    return {
        "Resource Consent Numbers": rc_str, "Company Name": company_str, "Address": address_str,
        "Issue Date": issue_date_str, "Expiry Date": expiry_date_str,
        "Reason for Consent": proposal_str, "Consent Conditions": conditions_str,
        "AUP(OP) Triggers": " ".join(re.findall(r"(E14\.\d+\.\d+|NES:STO|NES:AQ)", text)),
        "Text Blob": text
    }

# --- AI Chat & Logging Functions ---
def log_ai_chat(question, answer):
    """Logs the AI chat interaction to a CSV file."""
    # This function is well-written and remains unchanged.
    pass

# --- SIDEBAR & FILE UPLOAD ---
st.sidebar.title("Control Panel")
model_name = st.sidebar.selectbox("Choose Embedding Model:", ["all-MiniLM-L6-v2", "multi-qa-MiniLM-L6-cos-v1"])
uploaded_files = st.sidebar.file_uploader("Upload Consent PDFs", type=["pdf"], accept_multiple_files=True)
query_input = st.sidebar.text_input("Semantic Search Query", placeholder="e.g., 'dust management plan'")

@st.cache_resource
def load_embedding_model(name):
    return SentenceTransformer(name)

embedding_model = load_embedding_model(model_name)

# --- MAIN APP LOGIC ---
display_header()

if not uploaded_files:
    st.info("Please upload one or more Auckland Council air discharge consent PDF files to begin.")
    st.stop()

# Process Files
all_data = []
for file in uploaded_files:
    try:
        file_bytes = file.read()
        with fitz.open(stream=file_bytes, filetype="pdf") as doc:
            text = "".join(page.get_text() for page in doc)
        
        # Use AI extraction with regex as a fallback
        data = extract_metadata_with_llm(text, file.name)
        if not data:
            data = extract_metadata_regex(text)

        if data:
            data["__file_name__"] = file.name
            data["__file_bytes__"] = file_bytes
            all_data.append(data)
    except Exception as e:
        st.error(f"Critical error processing {file.name}: {e}")

if not all_data:
    st.error("Could not extract data from any of the uploaded files. Please check the file formats.")
    st.stop()

# --- DATA TRANSFORMATION & ANALYSIS ---
with st.spinner("Analyzing data and generating dashboard..."):
    df = pd.DataFrame(all_data)

    # --- Date Handling ---
    df['Issue Date'] = pd.to_datetime(df['Issue Date'], dayfirst=True, errors='coerce')
    
    def calculate_expiry(row):
        """Processes both absolute dates and relative durations for expiry."""
        expiry_info = row['Expiry Date']
        issue_date = row['Issue Date']
        if pd.isna(issue_date) or pd.isna(expiry_info):
            return pd.NaT
        if isinstance(expiry_info, str):
            year_match = re.search(r'(\d+)\s+years', expiry_info, re.IGNORECASE)
            if year_match:
                try:
                    return issue_date.replace(year=issue_date.year + int(year_match.group(1)))
                except ValueError: # Handles leap year edge cases
                    return issue_date + timedelta(days=365.25 * int(year_match.group(1)))
        return pd.to_datetime(expiry_info, dayfirst=True, errors='coerce')

    df['Expiry Date'] = df.apply(calculate_expiry, axis=1)

    # Localize dates to Auckland time
    df['Issue Date'] = df['Issue Date'].apply(localize_to_auckland)
    df['Expiry Date'] = df['Expiry Date'].apply(localize_to_auckland)
    
    # Geocode and set status
    df['Latitude'], df['Longitude'] = zip(*df['Address'].apply(geocode_address))
    df["Consent Status"] = df['Expiry Date'].apply(check_expiry)
    df["Consent Status Enhanced"] = df["Consent Status"]

    # Identify consents expiring soon
    ninety_days_from_now = datetime.now(pytz.timezone("Pacific/Auckland")) + timedelta(days=90)
    expiring_mask = (df["Consent Status"] == "Active") & (df["Expiry Date"] < ninety_days_from_now)
    df.loc[expiring_mask, "Consent Status Enhanced"] = "Expiring in 90 Days"

# --- RENDER DASHBOARD ---
st.subheader("Consent Summary Metrics")
col1, col2, col3, col4 = st.columns(4)
status_counts = df["Consent Status Enhanced"].value_counts()
col1.metric("Total Consents", len(df))
col2.metric("Active", status_counts.get("Active", 0))
col3.metric("Expiring in 90 Days", status_counts.get("Expiring in 90 Days", 0))
col4.metric("Expired", status_counts.get("Expired", 0))

# Visualizations
color_map = {"Unknown": "grey", "Expired": "#d9534f", "Active": "#5cb85c", "Expiring in 90 Days": "#f0ad4e"}
fig_status = px.bar(status_counts, y=status_counts.index, x=status_counts.values,
                    orientation='h', labels={'y': 'Status', 'x': 'Count'},
                    color=status_counts.index, color_discrete_map=color_map,
                    text=status_counts.values, title="Consent Status Overview")
fig_status.update_layout(showlegend=False, yaxis={'categoryorder':'total ascending'})
st.plotly_chart(fig_status, use_container_width=True)

# Data Table
with st.expander("Explore Consent Details", expanded=False):
    display_df = df.copy()
    display_df['Issue Date'] = display_df['Issue Date'].dt.strftime('%d-%b-%Y')
    display_df['Expiry Date'] = display_df['Expiry Date'].dt.strftime('%d-%b-%Y')
    st.dataframe(display_df[[
        "__file_name__", "Company Name", "Address", "Issue Date", "Expiry Date", "Consent Status Enhanced"
    ]].rename(columns={"__file_name__": "File Name", "Consent Status Enhanced": "Status"}))

# Map
with st.expander("Consent Location Map", expanded=True):
    map_df = df.dropna(subset=["Latitude", "Longitude"])
    if not map_df.empty:
        map_df['Expiry Date Str'] = map_df['Expiry Date'].dt.strftime('%d-%b-%Y')
        fig_map = px.scatter_mapbox(
            map_df, lat="Latitude", lon="Longitude", zoom=9.5,
            hover_name="Company Name", hover_data={"Address": True, "Consent Status Enhanced": True, "Expiry Date Str": True},
            color="Consent Status Enhanced", color_discrete_map=color_map, size_max=15)
        fig_map.update_layout(mapbox_style="carto-positron", margin={"r":0,"t":0,"l":0,"b":0}, legend_title_text='Status')
        st.plotly_chart(fig_map, use_container_width=True)

# Semantic Search & AI Chatbot sections can now be added here...
# (The existing code for these sections is solid and can be reused)

st.markdown("---")
st.caption("Built by Earl Tavera & Alana Jacobson-Pepere | Auckland Air Discharge Intelligence ¬© 2025")
